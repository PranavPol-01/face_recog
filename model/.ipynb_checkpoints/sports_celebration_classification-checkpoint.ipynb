{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3bda7-0c79-48f2-821d-d1eed6bd1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab9e21-f31b-4d57-91b2-4cbbfffff56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/sharapova1.jpg')\n",
    "img.shape\n",
    "\n",
    "# for filename in os.listdir('./test_images'):\n",
    "#     imgs = cv2.imread(os.path.join('./test_images', filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b5a10-bc21-492b-a464-9dcc03e7d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b772e9b-31a1-4d69-be88-63281c368a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60227fa-1385-49c5-a5b2-5bd94253b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0616d7-6192-4a7b-a6ac-aa8846295919",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e4a48-68a1-4bdc-84b4-4798b5786b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a2c1e-7982-4006-9e88-7cdf602e4447",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grey ,cmap='gray' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c807ec-f19f-48a3-99e9-b2f050973a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(grey ,1.3,5)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156b914-1718-4df4-b59b-787dfe460c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74f324-c233-47c0-a397-7ccb1d29d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,w,h) = faces[0]\n",
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc687d14-207b-4aa4-89d7-91ac2b9949e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1d40c-490f-47c3-9f9b-f2f12fbb7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "for (x,y,w,h) in faces:\n",
    "    face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_grey = grey[y:y+h, x:x+w]\n",
    "    roi_color = face_img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_grey)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(face_img, cmap='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d6610-6e3c-4d1e-8f5c-efaff11f0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi_color,cmap = 'grey')\n",
    "# roi = region of intrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b414a9b-b17a-4678-817d-53dd4ba37552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi_color,cmap = 'grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c8eb5-765e-41c0-a268-521700d8feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b48367-bfaa-4904-ad93-61ad58c7f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('./test_images/sharapova1.jpg')\n",
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca4a06-42ee-4e5f-9caf-b2ae0335dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = get_cropped_image_if_2_eyes('./test_images/sharapova1.jpg')\n",
    "plt.imshow(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c00ab34-c454-47c3-a70a-3fe242c9a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img_obstruct = cv2.imread('./test_images/sharapova1.jpg')\n",
    "plt.imshow(org_img_obstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e85ea-20e1-4153-8fe3-63f5b4c2ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_no_2_eyes = get_cropped_image_if_2_eyes('./test_images/sharapova2.jpg')\n",
    "cropped_image_no_2_eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424425a-63a7-4e18-839c-69e585798868",
   "metadata": {},
   "source": [
    "#### Above cropped_image_no_2_eyes is None which means we should ignore this image and we will not use such image for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2bab0-78a1-4c2a-b7d7-9edea30673ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./dataset/\"\n",
    "path_to_cr_data = \"./dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c27d43-f1cb-4db4-b7da-07ae6d651b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14000f-0dc8-4bae-b51f-56484e5abc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307387e6-c777-4188-a5c2-cbe113364116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create crop folder\n",
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257be8f-2c2f-4269-84e5-e633c0c538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1fdb6-bfb1-4f0f-992b-e530acdd4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            # if not os.path.exists(cropped_folder):\n",
    "            #     os.makedirs(cropped_folder)\n",
    "            #     cropped_image_dirs.append(cropped_folder)\n",
    "            #     print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a9e27-0f1f-4352-b64c-e7094a801d13",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d808b3-b9d4-499c-a5e0-c6073bf579c5",
   "metadata": {},
   "source": [
    "### wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25611a9-b3c2-4eaf-ad9b-3b36359d72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bc5bb-035c-47f5-99bf-229a20b456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img = np.array(roi_color)\n",
    "cropped_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2492360-88f2-4e32-8acb-2f58885dcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_har = w2d(original_image,'db1',5)\n",
    "plt.imshow(im_har, cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2b07d-6d2a-4dee-865c-0f914c4889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    celebrity_file_names_dict[celebrity_name] = file_list\n",
    "celebrity_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9881880-39e6-41e2-8d4f-032afb0a8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e572ab-ce58-4e7e-80db-dee16aee0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b147c72-84f0-4170-9e30-df84e89c7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print( len(X))\n",
    "pixel =len(X[0])\n",
    "print(pixel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8246fae-eb84-42af-a730-02102504f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f9aea-e9c7-4567-afca-cc1803eee0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28460cbb-ce02-4ada-a56e-dd0febb0387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a494d-a07b-48f7-8f44-8965f422e156",
   "metadata": {},
   "source": [
    "### Data cleaning process is done. Now we are ready to train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ccdfa-efc5-4eff-9ef1-cec38bc2ea63",
   "metadata": {},
   "source": [
    "##### We will use SVM with rbf kernel tuned with heuristic finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da10f2e-35fb-47f5-b43c-7af1ad55514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4127c3-e592-4bab-b5ae-790545ac29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea8e1d-ca5a-400d-a32b-226c9ea8484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cfd0d-ff59-4942-9539-dfd675048aa3",
   "metadata": {},
   "source": [
    "#### Grid search cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698aa07-3d1d-4b42-914f-f6b29bcbc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839992a7-c215-4d3e-8dbb-1e64ee7a0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33229e9f-4a20-4a12-bee7-bcb19676c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e82ed-9f0d-4e3c-bc32-45f7f4829eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d491a9-00a3-4727-a420-50e575daf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619ef29-c53a-4937-9469-37a1fdfba0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4740aac-96c7-4b40-8c94-cb16330f18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd1bd3-c40f-4059-984c-33d26779ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593c141-a9ff-4160-9bd0-996ac33c1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e76c5-46b0-4a87-8b80-14341654076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173a110-7afa-4f57-8bf4-8785688a52a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
